# 07 Escalado <!-- omit in toc -->

# 1. Eliminar el cluster existente
- Eliminar el resource group del CLUSTER

# 2. Habilitar VPA
## 2.1. Opción 2: Crear cluster con plugin VPA activado
```sh
az aks create -n aks<ESTUDIANTE> -g rgaks --enable-vpa -c 1 --generate-ssh-keys
```
Resultado
```
  "workloadAutoScalerProfile": {
    "keda": null,
    "verticalPodAutoscaler": {
      "enabled": true
    }
  }
```
```sh
az aks get-credentials --resource-group rgaks --name <CLUSTER_NAME> --overwrite-existing
```

## 2.2. Opción 1:  Actualizar cluster existente
```sh
az aks update --name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --enable-vpa
```

## 2.3. Revisar pods VPA
```
kubectl get pod -n kube-system | grep vpa
```

# 3. Crear  el recurso Vertical Pod Autocaler
> [Info](https://learn.microsoft.com/en-us/azure/aks/use-vertical-pod-autoscaler)

- vpa.yaml
```yaml
apiVersion: "autoscaling.k8s.io/v1"
kind: VerticalPodAutoscaler
metadata:
  name: hamster-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: hamster
	updatePolicy:
    updateMode: "Auto"  # Recreate = permite eliminar pods para recalcular recursos.
  resourcePolicy:
    containerPolicies:
      - containerName: '*'
        minAllowed:
          cpu: 100m
          memory: 50Mi
        maxAllowed:
          cpu: 1
          memory: 500Mi
        controlledResources: ["cpu", "memory"]
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hamster
spec:
  selector:
    matchLabels:
      app: hamster
  replicas: 2
  template:
    metadata:
      labels:
        app: hamster
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
      containers:
        - name: hamster
          image: registry.k8s.io/ubuntu-slim:0.1
          resources:
            requests:
              cpu: 100m
              memory: 50Mi
          command: ["/bin/sh"]
          args:
            - "-c"
            - "while true; do timeout 0.5s yes >/dev/null; sleep 0.5s; done"
```
## 3.1. Validar pods
```sh
kubectl get pods
kubectl describe pods hamster-xxx
```
Resultado
```
    Requests:
      cpu:        100m
      memory:     50Mi
```
## 3.2. Validar vpa
```sh
kubectl get vpa

kubectl describe vpa/hamster-vpa

```
Resultado:
```
NAME          MODE   CPU    MEM    PROVIDED   AGE
hamster-vpa   Auto   100m   50Mi   True       85s
```

```
  Recommendation:
    Container Recommendations:
      Container Name:  hamster
      Lower Bound:
        Cpu:     111m
        Memory:  50Mi
      Target:
        Cpu:     587m
        Memory:  50Mi
      Uncapped Target:
        Cpu:     587m
        Memory:  11500k
      Upper Bound:
        Cpu:     1
        Memory:  500Mi
```

> Lower Bound: no se recomienda bajar de estos valores para evitar errores de "recursos insuficientes"
> Target: Valores óptimos de consumo y desempeño
> Uncapped Target: Alternativa de consumo sin respetar el minAllowed & maxAllowed
> Upper Bound: recomendación máxima de valores.


# 4. Validar los recursos del pod
```sh
kubectl describe pods hamster-xxx
```
Resultado esperado:
```
    Requests:
      cpu:        587m
      memory:     50Mi
```
>  El request de cpu incrementó automáticamente

```sh
kubectl get pods -l app=hamster
```
Resultado
```
NAME                      READY   STATUS    RESTARTS   AGE
hamster-c6967774f-4sjk4   1/1     Running   0          10m
hamster-c6967774f-m7j5g   0/1     Pending   0          9m20s
```
> Si el cluster no tiene mas recursos los pods quedarán "Pending" ya que el request supera los recursos actuales

> El node pool creado en este laboratorio solo tiene un nodo en modo "Scale method": "Manual"

## 4.1. Revisar el node pool
- Node pool - Overview - Scale node pool
- Cancelar y regresar.


# 5. Cluster Autoscaler

## 5.1. Habilitar el node pool con autoscaler.
- AKS - Node pool - Scale node pool

## 5.2. Opcional: Crear un nuevo node pool con autoscaler habilitado desde CLI
```sh
az aks nodepool add -g rgaks --cluster-name <CLUSTER_NAME> --name autoscaler --enable-cluster-autoscaler --min-count 1 --max-count 2 -c 1
```
>  Es posible que la suscripción de estudiante no tenga recursos para desplegar.

## 5.3. Validar los nodos
```sh
kubectl get nodes -w
```

## 5.4. Validar el estado del pod "Pending"
```sh
kubectl get pods -l app=hamster -w
```

# 6. Opcional: KEDA - Event driven autoscale
> [Info](https://learn.microsoft.com/en-us/azure/aks/keda-about)
```sh

az aks update --name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --enable-keda
```

> En caso de error MSI (Managed Service Identity)
```sh
az aks update --name <CLUSTER_NAME> --resource-group <RESOURCE_GROUP> --enable-managed-identity
```

## 6.1. Metrics server
```
k get pods -n kube-system
```
Resultado
```
NAME                                               READY   STATUS    RESTARTS        AGE
keda-operator-metrics-apiserver-58c8cbcc85-g29c6   1/1     Running   1 (3m47s ago)   3m55s
keda-operator-metrics-apiserver-58c8cbcc85-w5mdl   1/1     Running   1 (3m48s ago)   3m56s
metrics-server-7b685846d6-mgz4d                    2/2     Running   0               20m
metrics-server-7b685846d6-nvhcs                    2/2     Running   0               20m
```

## Agregar el repo de Helm
```

helm repo add kedacore https://kedacore.github.io/charts
helm repo update
helm install http-add-on kedacore/keda-add-ons-http --namespace kube-system
```

```yaml
# Deployment of nginx, to be scaled by Keda http-add-on

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-http
spec:
  selector:
    matchLabels:
      app: nginx-http
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-http
    spec:
      containers:
        - name: nginx-http
          image: nginx
          resources:
            limits:
              memory: 10Mi
              cpu: 5m
          ports:
            - containerPort: 80

---

# Expose nginx deployment as a service, to connect to it and generate load

apiVersion: v1
kind: Service
metadata:
  name: nginx-http-service
  labels:
    app: nginx-http
spec:
  selector:
    app: nginx-http
  ports:
    - protocol: TCP
      port: 8082
      targetPort: 80

---

# The HTTPScaledObject configuration that will scale the nginx-http deployment
# when there are more than 10 pending request to it.
# minimum replica is 1 and max is 20

kind: HTTPScaledObject
apiVersion: http.keda.sh/v1alpha1
metadata:
    name: nginx-http
spec:
    hosts:
		- "nginx-http.default.svc.cluster.local"
    targetPendingRequests: 3
        deployment: nginx-http
        service: nginx-http-service
        port: 8082
    replicas:
      min: 1
      max: 8

---

# deployment use to generate traffic on our application
# the traffic needs to be generated to the keda keda-add-ons-http-interceptor-proxy service on port 8080!
# the keda-add-ons-http-interceptor-proxy service will forward the traffic to the configured application service - nginx-http-service

apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: load-http
  name: load-http
spec:
  replicas: 1
  selector:
    matchLabels:
      app: load-http
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: load-http
    spec:
      containers:
      - image: ubuntu:22.04
        command: ["/bin/sh"]
        args: ["-c","/usr/bin/apt update ; /usr/bin/apt install siege -y ; siege -d 1 -c 10 -t 300s -H 'Host: nginx-http.default.svc.cluster.local' http://keda-add-ons-http-interceptor-proxy.kube-system.svc.cluster.local:8080"]
        imagePullPolicy: Always
        name: load-http
        resources:
          limits:
            memory: 128Mi
            cpu: 200m
```

## Validar keda
```sh
k get HTTPScaledObject
```

## logs
```sh
k logs -f load-http-xxxx
```

## HPA
```sh
k get hpa
```
